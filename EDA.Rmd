---
title: "Spooky Author Identification - simple EDA"
output: 
  html_document: 
    fig_height: 6
    fig_width: 8
    toc: yes
---


```{r include=FALSE}
# chunks options
knitr::opts_chunk$set(message = FALSE, error = FALSE, warning = FALSE)
```

# Scores

* Random Forest with 1% of terms (including stopwords) in DTM 0.99658 
* Random Forest with 100% of terms (including stopwords) in DTM ...

# Plan of attack:

1. Check data
2. Count words for each author
3. Prepare word clouds for each author
4. Document Term Matrix
5. PCA for DTM
6. Decission Trees for DTM
7. XGBoost for DTM


# Preparation

**Get some packages:**

```{r message=FALSE, warning=FALSE}
library(data.table) # for fread()

library(tidyverse)
library(tidytext)
library(stringr)

library(wordcloud)
library(tm)
library(corrgram)

library(randomForest) # random forest
library(e1071) # SVM & Naive Bayes
library(xgboost) # XGBoost
```

**Load data**

```{r}
train <- fread("./input/train.csv")
test <- fread("./input/test.csv")
```


# Check data

**What's inside?**

Train dataset:

```{r}
glimpse(train)
```


Test dataset:

```{r}
glimpse(test)
```

Does documents from train exists in test?

```{r}
length(intersect(train$id, train$id))
```

0 means no.


**How many authors do we have?**

```{r}
unique(train$author)
```

Are ids are unique?

```{r}
length(unique(train$id)) == nrow(train)
length(unique(test$id)) == nrow(test)
```

Double TRUE - IDs are unique in both datasets.



# Count words for each author

Let's count words for each author

```{r}
train_words_author <- train %>%
   unnest_tokens(word, text) %>%
   # remove stopwords
   anti_join(stop_words, by = "word") %>%
   count(author, word) %>%
   ungroup()
```

# Word clouds

Let's see word cloud for all authors togheter

Prepare data:

```{r}
train_words_all <- train_words_author %>%
   group_by(word) %>%
   summarise(n = sum(n)) %>%
   ungroup()
```

Show word cloud:

```{r}
wordcloud(train_words_all$word, train_words_all$n,
          max.words = 200, scale = c(1.8, 0.5),
          colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9])
```

Show barplot for top 50 words (by frequency):

```{r}
theme_set(theme_minimal())

train_words_all %>%
   top_n(50, n) %>%
   arrange(n) %>%
   mutate(word = factor(word, levels = word)) %>%
   ggplot() +
      geom_col(aes(word, n), color = "gray80", fill = "lightgreen") +
      coord_flip()

rm(train_words_all) # won't be needed
```

# Prepare word clouds for each author

At the begining - two functions for plots:

```{r}
# word cloud
AuthorWordCloud <- function(author_id) {
   train_words_author %>%
      filter(author == author_id) %>%
      with(wordcloud(word, n, max.words = 200,
                     scale = c(1.8, 0.5),
                     random.order = FALSE,
                     rot.per = 0, 
                     colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9]))
}

# bar plot
AuthorWordBars <- function(author_id) {
   train_words_author %>%
      filter(author == author_id) %>%
      top_n(50, n) %>%
      arrange(n) %>%
      mutate(word = factor(word, levels = word)) %>%
      ggplot() +
         geom_col(aes(word, n), color = "gray80", fill = "lightgreen") +
         coord_flip() +
         labs(title = paste0("Most frequent words used by ", author_id))
}
```

## Word cloud for EAP:

```{r}
AuthorWordCloud("EAP")
```

## Barplot for EAP:

```{r}
AuthorWordBars("EAP")
```

## Word cloud for HPL:

```{r}
AuthorWordCloud("HPL")
```

## Barplot for HPL:

```{r}
AuthorWordBars("HPL")
```

## Word cloud for MWS:

```{r}
AuthorWordCloud("MWS")
```

## Barplot for MWS:

```{r}
AuthorWordBars("MWS")
```


Top 20 words and how often authors used them?

```{r fig.height=10}
train_words_author %>%
   group_by(author) %>%
   top_n(20, n) %>%
   ungroup() %>%
   group_by(word) %>%
   mutate(tot_n = sum(n)) %>%
   ungroup() %>%
   arrange(desc(tot_n)) %>%
   mutate(word = factor(word, levels = rev(unique(word)))) %>%
   ggplot() +
   geom_point(aes(author, word, size = n, color = n), show.legend = FALSE) +
   geom_text(aes(author, word, label = n), hjust = -1) +
   scale_color_distiller(palette = "YlOrRd") +
   scale_size_continuous(range = c(1, 10))
```

Who uses which word?

```{r}
train_words_author %>%
   group_by(author) %>%
   top_n(30, n) %>%
   ungroup() %>%
   group_by(word) %>%
   mutate(p = n/sum(n)) %>%
   ungroup() %>%
   ggplot() +
      geom_col(aes(word, p, fill = author), color = "gray80") +
      theme(axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1),
            legend.position = "bottom")
```


**Similarity of authors:**

```{r}
words_prob <- train_words_author %>%
   spread(author, n, fill = 0) %>%
   na.omit()

words_prob2 <- train_words_author %>%
   spread(word, n, fill = 0) %>%
   na.omit()

corrgram(words_prob, lower.panel = panel.shade, upper.panel = panel.cor)
```

Does it mean anything? I don't know yet :)


**Similarity of words** (20 most popular of them):

```{r}
words_prob2 <- train_words_author %>%
   top_n(20, n) %>%
   spread(word, n, fill = 0) %>%
   na.omit()

corrgram(words_prob2, lower.panel = panel.shade, upper.panel = panel.cor)

rm(train_words_author, words_prob, words_prob2) # won't be needed
```

Does it mean anything? I don't think so, but it look interesting :)


# Document Term Matrix

```{r}
train_dtm <- train %>%
   unnest_tokens(word, text) %>%
   count(author, id, word) %>%
   ungroup() %>%
   cast_dtm(id, word, n)

train_dtm
```

We have big matrix with `r train_dtm$nrow` documents (as rows) and `r train_dtm$ncol` words (as columns).

For a while we can make it smaller by removing about 99% of columns (those sparse ones):

```{r}
train_dtm_small <- removeSparseTerms(train_dtm, 0.99)
train_dtm_small
```

With this smaller matrix we can do

# PCA for DTM

```{r}
train_dtm_small_mat <- as.matrix(train_dtm_small)

pca <- princomp(train_dtm_small_mat, cor = TRUE)

pca_scores <- pca$scores %>%
   as.data.frame() %>%
   rownames_to_column("id") %>%
   left_join(train %>% select(id, author_name = author), by = "id")

pca_scores %>%
   ggplot() +
   geom_point(aes(Comp.1, Comp.2, color = author_name), show.legend = FALSE) +
   facet_wrap(~author_name)

rm(pca, pca_scores) # remove them
```

So PCA seems to be useless...

Mayby k-means then?

# K-means fot DTM

```{r}
train_dtm_small_df <- train_dtm_small_mat %>%
   as.data.frame() %>%
   rownames_to_column("id") %>%
   left_join(train %>% select(id, author_name = author), by = "id")

rm(train_dtm_small_mat) # save some memory :)


train_dtm_small_df$kmeans_cluster <- kmeans(train_dtm_small_df %>% select(-id, -author_name), 3)$cluster

train_dtm_small_df %>%
   count(kmeans_cluster, author_name) %>%
   ungroup() %>%
   ggplot() +
   geom_tile(aes(kmeans_cluster, author_name, fill = n), color = "gray80") +
   scale_fill_distiller(palette = "YlOrRd")
```

Is also looks useless.


# Decission Trees for DTM

```{r randomforest_model}
# for tests
train_dtm_small_rf <- train_dtm_small_df %>%
   select(-id, -kmeans_cluster) %>%
   mutate(author_name = factor(author_name))

# for competiton
# needs a lot of memory!
# train_dtm_small_rf <- as.matrix(train_dtm) %>%
#    as.data.frame() %>%
#    rownames_to_column("id") %>%
#    left_join(train %>% select(id, author_name = author), by = "id") %>%
#    select(-id) %>%
#    mutate(author_name = factor(author_name))

rm(train_dtm_small_df)

# need to change columnames
colnames(train_dtm_small_rf) <- paste0(colnames(train_dtm_small_rf), "_word")
train_dtm_small_rf <- rename(train_dtm_small_rf, author_name = author_name_word)


model_rf <- randomForest(author_name ~ .,
                         # do not use sample_frac in competition!
                         train_dtm_small_rf %>% sample_frac(0.1),
                         ntree = 50,
                         mtry = 6,
                         proximity = TRUE,
                         importance = TRUE)
```

Look at confusion matrix:

```{r}
model_rf$confusion
```

Variables importance:

```{r}
varImpPlot(model_rf)
```

Mostly stop words - it doesn't dobe well...


But we need to check this. Fisrt prepare test data:

```{r}
words_in_train <- train_dtm_small$dimnames$Terms

test_dtm_df <- test %>%
   unnest_tokens(word, text) %>%
   count(id, word) %>%
   ungroup() %>%
   filter(word %in% words_in_train) %>%
   mutate(word = paste0(word, "_word")) %>%
   cast_dtm(id, word, n) %>%
   as.matrix() %>%
   as.data.frame() %>%
   rownames_to_column("id")
```

**Predict:**

```{r randomforest_predict}
test_pred_rf <- predict(model_rf, newdata = test_dtm_df, type = "prob")

test_pred_rf <- cbind(test_dtm_df["id"], test_pred_rf)
```

Do we have all IDs from test dataset in our predictions?

```{r}
nrow(test_pred_rf) == nrow(test)
```

No, something is missing :( What is it:

```{r eval=FALSE}
filter(test, !id %in% test_pred_rf$id)
```

So let's add dummy variables for missing IDs:

```{r}
dummy <- test %>%
   filter(!id %in% test_pred_rf$id) %>%
   select(id) %>%
   mutate(EAP = 1/3,
          HPL = 1/3,
          MWS = 1/3)

test_pred_rf_submit <- bind_rows(test_pred_rf, dummy)
```

Check once more time:

```{r}
nrow(test_pred_rf_submit) == nrow(test)
filter(test, !id %in% test_pred_rf_submit$id)
```

Same number of rows, no missing ID - we can submit our prediction!

```{r}
fwrite(test_pred_rf_submit, file = "submit_RandomForest.csv")

rm(model_rf, test_pred_rf, dummy, test_pred_rf_submit)

```


# Navie Bayes for DTM

```{r naivebayes}
model_nb <- naiveBayes(author_name ~ .,
                       data = train_dtm_small_rf,
                       type = "raw")

pred_bayes <- predict(model_nb, newdata = test_dtm_df %>% select(-id), type = "raw")

test_pred_bayes <- cbind(test_dtm_df["id"], pred_bayes)


dummy <- test %>%
   filter(!id %in% test_pred_bayes$id) %>%
   select(id) %>%
   mutate(EAP = 1/3,
          HPL = 1/3,
          MWS = 1/3)

test_pred_bayes_submit <- bind_rows(test_pred_bayes, dummy)

fwrite(test_pred_bayes_submit, file = "submit_NaiveBayes.csv")

rm(model_nb, pred_bayes, test_pred_bayes, dummy, test_pred_bayes_submit)
```



# Support Vector Machines on DTM

```{r svm}
model_svm <- svm(author_name ~ .,
                 data = train_dtm_small_rf %>% sample_frac(0.1),
                 type = "nu-classification",
                 probability = TRUE)

pred_svm <- predict(model_svm, newdata = test_dtm_df %>% select(-id), probability = TRUE)

test_pred_svm <- cbind(test_dtm_df["id"], attr(pred_svm, "probabilities"))


dummy <- test %>%
   filter(!id %in% test_pred_svm$id) %>%
   select(id) %>%
   mutate(EAP = 1/3,
          HPL = 1/3,
          MWS = 1/3)

test_pred_svm_submit <- bind_rows(test_pred_svm, dummy)

fwrite(test_pred_svm_submit, file = "submit_SVM.csv")
```


# XGBoost for DTM

```{r xgboost}
xgb_train <- train_dtm_small_rf %>% sample_frac(0.1)

xgb_train_X <- xgb_train %>% select(-author_name) %>% as.matrix() 
xgb_train_Y <- as.numeric(xgb_train$author_name)-1


xgb_params = list(
   objective = "multi:softprob",
   num_class = 3,
   booster = "gbtree",
   eta = 0.1,
   max_depth = 6,
   subsample = 0.8
)



model_xgb <- xgb.train(data = xgb.DMatrix(xgb_train_X, label = xgb_train_Y),
				  params = xgb_params,
				  nrounds = 50,
				  verbose = 1)


xgb_test <- test_dtm_df %>% select(-id) %>% as.matrix()

pred_xgb <- predict(model_xgb, xgb_test) %>% matrix(ncol = 3)


test_pred_xgb <- cbind(test_dtm_df["id"], pred_xgb)

colnames(test_pred_xgb) <- c("id", "EAP", "HPL", "MWS")

dummy <- test %>%
   filter(!id %in% test_pred_xgb$id) %>%
   select(id) %>%
   mutate(EAP = 1/3,
          HPL = 1/3,
          MWS = 1/3)

test_pred_xgb_submit <- bind_rows(test_pred_xgb, dummy)

fwrite(test_pred_xgb_submit, file = "submit_xgb.csv")
```

# Keras for DTM

TBD

