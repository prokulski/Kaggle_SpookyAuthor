---
title: "Spooky Author Identification - simple EDA"
output: 
  html_document: 
    fig_height: 6
    fig_width: 8
---


```{r include=FALSE}
# chunks options
knitr::opts_chunk$set(message = FALSE, error = FALSE, warning = FALSE)
```

# Plan of attack:

1. Check data
2. Count words for each author
3. Prepare word clouds for each author
4. Document Term Matrix
5. PCA for DTM
6. Decission Trees for DTM
7. XGBoost for DTM


# Check data

Get some packages:

```{r}
library(data.table) # for fread()

library(tidyverse)
library(tidytext)

library(wordcloud)
```

Load data

```{r}
train <- fread("./input/train.csv")
```

What's inside?

```{r}
glimpse(train)
```

Who many authors do we have?

```{r}
unique(train$author)
```

Are ids are unique?

```{r}
length(unique(train$id)) == nrow(train)
```

TRUE :)


# Count words for each author

Let's count words for each author

```{r}
train_words_author <- train %>%
   unnest_tokens(word, text) %>%
   anti_join(stop_words, by = "word") %>%
   count(author, word) %>%
   ungroup()
```


# Prepare word clouds for each author

## Word cloud for EAP:

```{r}
train_words_author %>%
   filter(author == "EAP") %>%
   with(wordcloud(word, n, max.words = 200, scale = c(1.8, 0.5), colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9]))
```

## Word cloud for HPL:

```{r}
train_words_author %>%
   filter(author == "HPL") %>%
   with(wordcloud(word, n, max.words = 200, scale = c(1.8, 0.5), colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9]))
```

## Word cloud for MWS:

```{r}
train_words_author %>%
   filter(author == "MWS") %>%
   with(wordcloud(word, n, max.words = 200, scale = c(1.8, 0.5), colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9]))
```


Top 20 words and how often authors used them?

```{r fig.height=10}
train_words_author %>%
   group_by(author) %>%
   top_n(20, n) %>%
   ungroup() %>%
   ggplot() +
   geom_tile(aes(author, word, fill = n), color = "gray80") +
   geom_text(aes(author, word, label = n)) +
   scale_fill_distiller(palette = "YlOrRd")
```

Who uses which word?

```{r}
train_words_author %>%
   group_by(author) %>%
   top_n(20, n) %>%
   ungroup() %>%
   group_by(word) %>%
   mutate(p = n/sum(n)) %>%
   ungroup() %>%
   ggplot() +
   geom_col(aes(word, p, fill = author), color = "gray80") +
   theme(axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1))
```

Let's see word cloud for all authors togheter

Prepare data:

```{r}
train_words_all <- train_words_author %>%
   group_by(word) %>%
   summarise(n = sum(n)) %>%
   ungroup()

```

Show cloud:

```{r}
wordcloud(train_words_all$word, train_words_all$n, max.words = 200, scale = c(1.8, 0.5), colors = RColorBrewer::brewer.pal(9, "YlOrRd")[3:9])
```

Similarity of authors:

```{r}
words_prob <- train_words_author %>%
   spread(author, n) %>%
   na.omit()

cor(words_prob[2:4])
```


# Document Term Matrix

```{r}
dtm <- train %>%
   unnest_tokens(word, text) %>%
   count(id, word) %>%
   ungroup() %>%
   bind_tf_idf(word, id, n) %>%
   left_join(train %>% select(id, author), by = "id") %>%
   select(author, id, word, tf_idf)

ggplot(dtm) + geom_density(aes(tf_idf)) + scale_x_log10()
```

We can cut tf_idf to greater than 1

```{r}
dtm_part <- dtm %>% filter(tf_idf > 1) %>% spread(word, tf_idf, fill = 0)
```

# PCA for DTM

```{r}
dtm_part_pca <- dtm_part[-2]
pca <- princomp(dtm_part_pca[2:nrow(dtm_part_pca)])

cbind(dtm_part_pca[1], pca$scores[,1:2]) %>%
   unique %>%
   ggplot() + geom_point(aes(Comp.1, Comp.2, color = author))
```


# Decission Trees for DTM
# XGBoost for DTM


TF-IDF

```{r}
train_words_author %>% 
   bind_tf_idf(word, author, n) %>%
   group_by(author) %>%
   top_n(30, tf_idf) %>%
   arrange(tf_idf) %>%
   mutate(word = factor(word, levels = unique(word))) %>%
   ungroup() %>%
   ggplot() +
   geom_col(aes(word, tf_idf, fill = author)) +
   facet_wrap(~author, scales = "free") +
   coord_flip()
```
